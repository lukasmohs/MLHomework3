---
output:
  pdf_document: default
  html_document: default
---
# Homework 3

## Part 1: Optimization (5 points)

Optimization underlies the determination of parameter settings based on minimization of an objective. We derived this for maximum likelihood of linear regression and showed a regularized version. In this exercise, we will use gradient descent to learn the parameters for logistic regression. Then we will impose a regularizer to keep the parameters closer to 0 in attempts to reduce variance.

```{r, quiet=T, message=F}
require(dplyr)
# Generate some data - do not change
set.seed(12345)
data.size = 1000
get_data = function(n=data.size) {
  df = data.frame(x1 = rnorm(n),x2=4*runif(n)-2) %>%
    tbl_df() %>%
    mutate(y = (x1^2+x2^2)<1) %>%
    mutate(y = (function(.) {.[runif(data.size)<0.1] = 0; .})(y)) %>%
    mutate(y = (function(.) {.[runif(data.size)<0.1] = 1; .})(y))
  df
}

df = get_data(data.size)

require(ggplot2)
ggplot(data = df, aes(x=x1,y=x2,color=y)) + geom_point() + coord_cartesian(xlim=c(-3,3), ylim=c(-3,3))

```

a. Perform logistic regression using glm or other package
```{r, quiet=T, message=F}
lr <- glm(formula = y  ~ .,
          family=binomial(link="logit"),data = df, control = list(maxit = 100))
```

b. Perform logistic regression using optim. Compare your parameters from optim to the glm parameters.
```{r, quiet=T, message=F}
linear_prediction = function(x1,x2, pars) {
  pars[1]+ pars[2]*x1 + pars[3]*x2
}
sq_loss = function(pars, y, x1,x2) {
  sum((y-linear_prediction(x1,x2,pars))^2) #toefte
}
opt <- optim(par=rep(0,3), fn=sq_loss, y=df$y, x1=df$x1, x2=df$x2)
opt$par
lr$coefficients
print("to compare the intercept:")
log(opt$par[1]/(1-opt$par[1]))
```

c. Perform logistic regression with L2 regularization
```{r, quiet=T, message=F}
sq_loss_l2_regularized = function(pars, y, x1, x2, lambda=100) {
  sq_loss(pars,y,x1,x2) + lambda*sum(pars[2]^2+pars[3]^2) # omit the intercept
}
optreg = optim(par=rep(0,3), sq_loss_l2_regularized, y=df$y, x1=df$x1, x2=df$x2)
optreg$par
```

d. Perform logistic regression using optim with quadratic terms
```{r, quiet=T, message=F}
linear_prediction = function(x1,x2, pars) {
  pars[1]+ pars[2]*x1 + pars[3]*x2
}
quadratic_term_prediction1 = function(x1,x2, pars) {
  (x1*pars[2] + x2*pars[3] + pars[1])^2
}
quadratic_term_prediction2 = function(x1,x2, pars) {
   pars[1] + x1* pars[2] + x2 * pars[3] + x1^2*pars[4] + x2^2 * pars[5] + x1*x2*pars[6]
}
sq_loss_quadratic = function(pars, y, x1, x2) {
  sum((y-quadratic_term_prediction2(x1,x2,pars))^2)
}
optquad <- optim(par=rep(0,6), fn=sq_loss_quadratic, y=df$y, x1=df$x1, x2=df$x2)
optquad$par

```

e. Perform logistic regression with L2 regularization with quadratic terms
```{r, quiet=T, message=F}
sq_loss_l2_regularized_quadratic = function(pars, y, x1, x2, lambda=100) {
  sq_loss_quadratic(pars,y,x1,x2) + lambda*sum(pars[2]^2+pars[3]^2)
}
optquadreg <- optim(par=rep(0,6), fn=sq_loss_l2_regularized_quadratic, y=df$y, x1=df$x1, x2=df$x2)
optquadreg$par
```

f. Create a learning curve for parts b, c, d, e. Interpret your learning curve.
```{r, quiet=T, message=F}
accuracies = data.frame(x = numeric(100), opt = numeric(100), optreg=numeric(100), optquad=numeric(100),optquadreg=numeric(100))
test = df[seq(nrow(df)/2,nrow(df),1),]
for (i in 1:100 ){
  optaccuracy = 0 
  optregaccuracy = 0 
  optquadaccuracy = 0 
  optquadregaccuracy = 0 
  train = df[seq(1,nrow(df)/2/100*i,1),]
  opt = optim(par=rep(0,3), fn=sq_loss, y=train$y, x1=train$x1, x2=train$x2)
  optreg = optim(par=rep(0,3), fn=sq_loss_l2_regularized, y=train$y, x1=train$x1, x2=train$x2)
  optquad = optim(par=rep(1,6), fn=sq_loss_quadratic, y=train$y, x1=train$x1, x2=train$x2)
  optquadreg = optim(par=rep(1,6), fn=sq_loss_l2_regularized_quadratic, y=train$y, x1=train$x1, x2=train$x2)
  for (c in 1:nrow(test)) {
    if((opt$par[1] + opt$par[2]*test$x1[c] + opt$par[3]*test$x2[c] >  mean(test$y)) == (test$y[c]==1 )) {
      optaccuracy = optaccuracy + 1
    }

    if((optreg$par[1] + optreg$par[2]*test$x1[c] + optreg$par[3]*test$x2[c] >  mean(test$y)) == (test$y[c]==1 )) {
      optregaccuracy = optregaccuracy + 1
    }
    if((optquadreg$par[1] + optquadreg$par[2]*test$x1[c] + optquadreg$par[3]*test$x2[c] + optquadreg$par[4]*test$x1[c]^2
          + optquadreg$par[5]*test$x2[c]^2 + optquadreg$par[6]*test$x2[c]*test$x1[c] >   mean(test$y)) == (test$y[c]==1 )) {
      optquadaccuracy = optquadaccuracy + 1
    }
    if((optquadreg$par[1] + optquadreg$par[2]*test$x1[c] + optquadreg$par[3]*test$x2[c] + optquadreg$par[4]*test$x1[c]^2
          + optquadreg$par[5]*test$x2[c]^2 + optquadreg$par[6]*test$x2[c]*test$x1[c] >   mean(test$y)) == (test$y[c]==1 )) {
      optquadregaccuracy = optquadregaccuracy + 1
    }
    accuracies$x[i] <- i
    accuracies$opt[i] <- optaccuracy/nrow(test)
    accuracies$optreg[i] <- optregaccuracy/nrow(test)
    accuracies$optquad[i] <- optquadaccuracy/nrow(test)
    accuracies$optquadreg[i] <- optquadregaccuracy/nrow(test)
  }
}

accuracies
ggplot(data = accuracies, aes(x)) + ylab("Accuracy") + xlab("Training Set Size (%)")  + geom_line(aes(y = opt, color="Logistic Regression(LR)")) + geom_line(aes(y = optreg, color="LR with L2 Regularization")) + geom_line(aes(y = optquad,color="LR based on quadratic terms")) + geom_line(aes(y = optquadreg,color="LR based on quadratic terms with L2 Regularization")) + coord_cartesian(xlim=c(0,100), ylim=c(0,1)) + scale_colour_manual("", breaks = c("Logistic Regression(LR)", "LR with L2 Regularization", "LR based on quadratic terms", "LR based on quadratic terms with L2 Regularization"), values = c("red", "green", "blue","violet"))


```


## Part 2: Machine Learning Methods: simulation of statin effect on heart attack occurrence (6 points)

Use the data generator ```source(homework3simulator.r)``` provided to conduct a simulation study on the effect of statin on MI (myocardial infarction/heart attack). The way the data generator works is it enumerates all possible states and associates each with a cell of the full joint distribution ```m``` of the form: ```c(feature vector, probability)```. Use ```get_data( nData , m )``` to sample ```nData``` examples.

Under the ground truth, what is the treatment effect of statins on MI?
```{r, quiet=T, message=F}
require(dplyr)
source("homework3simulator.r")
statin_sample <- get_data(1000,m)
ate = (sum(statin_sample$statin==0&statin_sample$mi==1)/sum(statin_sample$statin==0) - sum(statin_sample$statin==1&statin_sample$mi==1)/sum(statin_sample$statin==1)) * 100

print("The ATE (in %) evaluates to: ")
ate

```

Under the ground truth, what is the treatment effect of statins in patients with diabetes? Compare that to the treatment effect of statins in patients without diabetes.
```{r, quiet=T, message=F}
source("homework3simulator.r")
ate = (sum(statin_sample$diabetes==1&statin_sample$statin==0&statin_sample$mi==1)/sum(statin_sample$diabetes==1&statin_sample$statin==0) - sum(statin_sample$diabetes==1&statin_sample$statin==1&statin_sample$mi==1)/sum(statin_sample$diabetes==1&statin_sample$statin==1)) * 100

print("The ATE (in %) evaluates to: ")
ate
print("The treatment effect is roughly 1% higher for people with diabetes.")
```
*The treatment effect for people with diabetes is rougly 1-2% better than for people without diabetes*

Under the ground truth model, what is the cross entropy error of the optimal prediction function (hint: A. is there irreducible error, i.e., given x, can you perfectly predict y? B. Given the best you can do, how well do you do in expectation)?
```{r, quiet=T, message=F}
statinlr <- glm(formula = mi  ~ .,
          family=binomial(link="logit"),data = statin_sample, control = list(maxit = 100))
statinpreds = predict(object=statinlr, type="response", data=get_data(1000,m))
CEError = 0
for (i in 1:1000) {
  CEError = log(statinpreds[i])*statin_sample$mi[i] + CEError
}
CEError = CEError * -1
CEError
```
*By taking a sample set of 1000 instances, we can derice this linear model. From further 1000 test instances, the cross entropy error could be computed. Even if the prediciton works very good, the noise of the created data makes a perfect prediction impossible.*

Compare the performance of the following algorithms in prediction of MI: logistic regression, random forests, neural networks, and SVMs
Plot learning curves for 10, 30, 100, 300, 1000, 3000 training examples. Report any errors. Interpret your findings.
```{r, quiet=T, message=F}
library(ROCR)
source("homework3simulator.r")
cases = c(10,30,100,300,1000,3000)
plot_comparison = function(size){
  plot(LRROC, col="blue")
  plot(RFROC, add = TRUE, col="red")
  plot(SVMROC, add = TRUE, col="green")
  plot(NNROC, add = TRUE, col="violet")
  title(main=cbind("ROC Comparison of different Classifiers, with n= ",size))
  legend("bottomright",c("Logistic Regression","Random Forest","Support Vector Machine","Neural Network"),col=c("blue","red", "green","violet"), lwd=3, y.intersp = 1.0)
}


for (i in cases) {
  library(neuralnet)
  detach(package:neuralnet) #Killing the ROC prediction function...
  library(ROCR)
  
  statin_sample = get_data(i,m)
  statin_test = get_data(i,m)
  while(sum(statin_test$mi)==0 || sum(statin_sample$mi)==0) {
    statin_sample = get_data(i,m)
    statin_test = get_data(i,m)
  }
  
  ##Logistic Regression
  LR <- glm(formula = mi  ~ .,
            family=binomial(link="logit"),data = statin_sample, control = list(maxit = 100))
  LRPredictedProbabilities <- predict(LR, statin_test, type="response")
  LRPred <- prediction(LRPredictedProbabilities, statin_test$mi)
  LRROC <- performance(LRPred,"tpr","fpr")
  
  ##Random Forests
  library(randomForest)
  RF = randomForest(as.factor(mi==1) ~ ., statin_sample)
  RFPredictedProbabilities = predict(RF,statin_test, type="prob") 
  RFPred <- prediction(RFPredictedProbabilities[,2], statin_test$mi)
  RFROC <- performance(RFPred,"tpr","fpr")
  
  ##Neural Networks
  library(neuralnet)
  n = names(statin_sample)[-11]
  rhs = paste(names(statin_sample[-11]), collapse = " + ")
  formulaString = as.formula(paste0("mi~",rhs))
  #nnSpectTrain = statin_sample %>% mutate_all((function(x) (x-mean(x))/sd(x)))
  #nnSpectTest = statin_test %>% mutate_all(function(x) (x-mean(x))/sd(x)) 
  NN = neuralnet(formula = formulaString, 
                 data = statin_sample,#nnSpectTrain %>% mutate(mi=ifelse(mi>mean(mi),1,0)),
                 err.fct="ce",
                 act.fct="logistic",
                 linear.output = F,
                 hidden=c(1,2), # had to decrease since not converging
                 rep = 5,
                 stepmax=1e5)# takes a bit longer to converge :D
  NNPrdictedProbabilites = compute(NN,statin_test %>% select(-mi))$net.result 
  detach(package:neuralnet) #Killing the ROC prediction function...
  library(ROCR)
 
  NNPred <- prediction(NNPrdictedProbabilites, statin_test$mi)
  NNROC <- performance(NNPred,"tpr","fpr")
  
  
  ##SVM
  library(e1071)
  SVM = svm(mi ~ . , statin_sample)
  
  SVMPredictedProbabilities = predict(SVM, statin_test, type="prob") 
  SVMPred <- prediction(SVMPredictedProbabilities, statin_test$mi)
  SVMROC <- performance(SVMPred,"tpr","fpr")
  
  ##Plotting
  
  
plot_comparison(i)

}
```
*Unfortunately, the Neural Net sometimes doesn't converge. By reducing hidden layers and increasing the number of iterations as well as the step size, one can increase the probability of successful completion, but it remains uncertain.*
*Generally speaking, the performance of all algorithms remains indistinguishable for a small training data set, but with n>100, differences become visible. Especially the Logistic Regression seems to be the most suitable model for the given problem followed by the Random Forest and the Support Vecotr Machine. In case the Neural Net converges and doesn't crash, its results are comparably good or sometimes even best*


## Part 3: Survival Analysis (4 points)
Conduct survival analysis. For this we will use the "mgus" data set from ```library(survival); mgus```. MGUS is "monogammopathy of unknown significance", and it is a medical condition identified in asymptomatic individuals who receive blood tests. In some cases it can be a precursor to the blood cancer called multiple myeloma. For more information on the study, see: http://www.mayoclinicproceedings.org/article/S0025-6196(12)60015-9/pdf

Use glm and glmnet to conduct survival analysis with and without regularization. Describe the task and plot a Kaplan Meier curve; conduct your analysis; interpret your findings.
```{r, quiet=T, message=F}
library(survival)
survivalData = mgus %>% tbl_df()

KM = Surv(survivalData$futime, survivalData$death==1) %>%
  (function(x) survfit(x ~ 1, data=survivalData))(.)
# KM curve
plot(KM, xlab= "Days",ylab="P(survive)", mark.time=T)

# Cox Model
CM = Surv(survivalData$futime, survivalData$death==1) %>%
  (function(x) coxph(x ~  age  +  sex + dxyr + pcdx +alb + creat +  hgb + mspike , data=survivalData))(.)

"---------------------------"
"Coefficients of Cox Model: "
"---------------------------"
coef(CM)
# Reg Cox Model
library(glmnet)
survivalData["sex"] = ifelse(survivalData["sex"]=="male",1,0)
survivalData["pcdx"] = ifelse(survivalData["pcdx"]=="AM",1,0)
survivalData=survivalData %>% na.omit()
RCM = survivalData  %>%
  (function(x) glmnet(x %>% select(-id,-futime,-pctime,-death) %>%
                        as.data.frame() %>% as.matrix(),
                      Surv(survivalData$futime, survivalData$death==1),
                      family="cox"))(.)
"--------------------------------------"
"Coefficients of Regularized Cox Model: "
"--------------------------------------"
coef(RCM, s=0.05)
```
*From both calculated Cox Models we can derive that the gender of the patient seems to have the strongest influence on the time to mortality. In the non-regularized model, the size of the monoclonal protien spike at diagnosis (mspike) appears to be also predictive, meanwhile it is not as important in the regularized model. The subtype of plasma cell malignancy specification (pcdx), is also important within both models.*
*By analyzing the Kaplan-Meier curve, we can see that the probability to survive almost linearly decreases, which could be an indicator for relatively small chances to die due to MGUS. Especially considering the average age, which is quite high (around 60), increases the probability of other reasons for death within the next years (5000 days = 13.7 years).*
